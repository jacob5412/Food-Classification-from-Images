{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Classification from Images Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "Convolutional neural networks (CNN) have been widely used in automatic image classification systems. In most cases, features from the top layer of the CNN are utilized for classification; however, those features may not contain enough useful information to predict an image correctly. In some cases, features from the lower layer carry more discriminative power than those from the top. Therefore, applying features from a specific layer only to classification seems to be a process that does not utilize learned CNN’s potential discriminant power to its full extent. This inherent property leads to the need for fusion of features from multiple layers. To address this problem, we propose a method of combining features from multiple layers in given CNN models. Moreover, already learned CNN models with training images are reused to extract features from multiple layers. The proposed fusion method is evaluated according to image classification benchmark data sets, CIFAR-10, NORB, and SVHN. In all cases, we show that the proposed method improves the reported performances of the existing models by 0.38%, 3.22% and 0.13%, respectively.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "The Convolutional neural network(CNN) is a deep learning architecture that has numerous application in computer vision and natural language processing. The CNN classifies objects based on number of features matched.\n",
    "\n",
    "Steps involed in creating CNN\n",
    "    <ol>\n",
    "<li>Convolution</li>\n",
    "<li> Pooling</li>\n",
    "<li> Flattening</li>\n",
    "<li> Full Connection</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Dataset](convo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>Convolution</b>\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "ConvNets derive their name from the “convolution” operator. The primary purpose of Convolution in case of a ConvNet is to extract features from the input image. Convolution preserves the spatial relationship between pixels by learning image features using small squares of input data. \n",
    "</div>\n",
    "    </li>\n",
    "<li> <b>Pooling</b>\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "Spatial Pooling (also called subsampling or downsampling) reduces the dimensionality of each feature map but retains the most important information. Spatial Pooling can be of different types: Max, Average, Sum etc.\n",
    "In case of Max Pooling, we define a spatial neighborhood (for example, a 2×2 window) and take the largest element from the rectified feature map within that window. Instead of taking the largest element we could also take the average (Average Pooling) or sum of all elements in that window. In practice, Max Pooling has been shown to work better.\n",
    "</div>\n",
    "    </li>\n",
    "<li> <b>Flattening</b>\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "Convert the 2D matrix to a column vector so that it can passed through an artificial neural network\n",
    "</div>\n",
    "    </li>\n",
    "<li> <b>Full Connection</b>\n",
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "The Fully Connected layer is a traditional Multi Layer Perceptron that uses a softmax activation function in the output layer (other classifiers like SVM can also be used, but will stick to softmax in this post). The term “Fully Connected” implies that every neuron in the previous layer is connected to every neuron on the next layer.\n",
    "The output from the convolutional and pooling layers represent high-level features of the input image. The purpose of the Fully Connected layer is to use these features for classifying the input image into various classes based on the training dataset. \n",
    "</div>\n",
    "    </li>\n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Food Classification using keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import the libraries required by the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black # (optional) for code formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is located in folder named dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of three classes, french_fries, pizza and samosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"dataset.png\" alt = \"DataSet\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each folder contains approximately 1000 image files in each category. The name of the folder is actually the label of those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CNN\n",
    "classifier = Sequential()\n",
    "# Convolution and Max pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full connection\n",
    "classifier.add(Dense(128, activation=\"relu\"))\n",
    "classifier.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile classifier\n",
    "classifier.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting CNN to the images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"./dataset/training_set\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    \"./dataset/test_set\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=800 / 32,\n",
    "    epochs=50,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=200 / 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_set.class_indices\n",
    "labels = dict((v, k) for k, v in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import os\n",
    "\n",
    "target_dir = \"./models/\"\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "classifier.save(\"./models/model.h5\")\n",
    "classifier.save_weights(\"./models/weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a new image from url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries for creating GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model\n",
    "from PIL import Image, ImageTk\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import IPython\n",
    "from keras.preprocessing import image as image_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "    We now create a url and a button for browsing and loading image.\n",
    "The trained CNN is loaded and the saved parameters are restored.\n",
    "Prediction is made on the new image which is then output and \n",
    "the output is displayed on canvas.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "img_width, img_height = 128, 128\n",
    "model_path = \"./models/model.h5\"\n",
    "model_weights_path = \"./models/weights.h5\"\n",
    "model = load_model(model_path)\n",
    "model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_food(url):\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    test_image = Image.open(BytesIO(response.content))\n",
    "    put_image = test_image.resize((400, 400))\n",
    "    test_image = test_image.resize((128, 128))\n",
    "    test_image = image_utils.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = model.predict_on_batch(test_image)\n",
    "    for i in range(len(result[0])):\n",
    "        if result[0][i] == 1:\n",
    "            ans = labels[i]\n",
    "    if ans == \"\":\n",
    "        ans = \"Not a pizza, samosa nor french fries\"\n",
    "\n",
    "    print(\"Predicted answer : \" + ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.kingarthurflour.com/sites/default/files/recipe_legacy/20-3-large.jpg\"  # change to image url\n",
    "classify_food(url)\n",
    "IPython.display.Image(url, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"text-align: justify\">\n",
    "The performance of the system is high, and is considered\n",
    "acceptable from a usage point of view. However, the CNNs\n",
    "need high-performance computing machines in order to\n",
    "experiment on the huge multi-media datasets. The CNN\n",
    "is capable of train highly non-linear data, and for that in contrast, it takes more computational time to train the network.\n",
    "However, the performance matters a lot, and once the system\n",
    "is properly trained, the system can produce the results in less\n",
    "time. The images are properly preprocessed and all kinds of\n",
    "images are tested with CNN. From this, it is concluded that\n",
    "CNNs are more suitable for classifying the images when the\n",
    "number of classes are more.\n",
    "The task of image classification can be extended using\n",
    "prominent features that can categorize food images. Since\n",
    "the CNNs are consuming high computational time, the\n",
    "feature-based approach is highly appreciable. A multi-level\n",
    "classification approach (hierarchical approach) is suitable to\n",
    "avoid mis-classifications when the number of classes is more.\n",
    "Moreover, a dataset containing all food categories is also not\n",
    "available in the literature yet.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8228338\n",
    "<br>\n",
    "[2] https://keras.io/\n",
    "<br>\n",
    "[3] https://www.tensorflow.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
